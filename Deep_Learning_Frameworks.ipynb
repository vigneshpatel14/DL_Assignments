{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODhRrKoA+JxuzzgUqMO62m"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1) What is TensorFlow 2.0, and how is it different from TensorFlow 1.x2**"
      ],
      "metadata": {
        "id": "JFO27LqOrsOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensorflow 2.0 is an update to tensorflow , it introduced many features to improve usability , efficiency and developer experience compared to tensorflow 1.0."
      ],
      "metadata": {
        "id": "XLMY7zOJr3wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2) How do you install TensorFlow 2.0**"
      ],
      "metadata": {
        "id": "y3QsBqOwsSXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "run this command to install tensorflow\n",
        "\n",
        "pip install tensorflow==2.0"
      ],
      "metadata": {
        "id": "IwXV-KdYsjxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3) What is the primary function of the tf.function in TensorFlow 2.0**"
      ],
      "metadata": {
        "id": "BU-D6UCussLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's main purpose is to convert python function into TensorFlow computational graphs for performance optimization.This allows tensorflow to execute codes faster by leveraging graph based execution ."
      ],
      "metadata": {
        "id": "auLi6xO2s4sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4) What is the purpose of the Model class in TensorFlow 2.0**"
      ],
      "metadata": {
        "id": "zYvatxNQtPMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a part of tf.keras module that serves as an abstraction for building models\n",
        "\n",
        "The model class provides flexible frameworks for creating deep learning models . It has a lot of features like fit , evaluate and predict"
      ],
      "metadata": {
        "id": "u1ITxL18tYQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5) How do you create a neural network using TensorFlow 2.0**"
      ],
      "metadata": {
        "id": "b8pX2c3ktx35"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "grhA8To5rnUl"
      },
      "outputs": [],
      "source": [
        "#Import the libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#Load the dataset\n",
        "\n",
        "#Define the neural network model\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "#Add layers then compile the model , fit the model and evaluate , predict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6) What is the importance of Tensor Space in TensorFlow**"
      ],
      "metadata": {
        "id": "eK2pFAfMuftO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor space in TensorFlow is the core structure for representing data as multidimensional arrays (tensors). It allows for efficient mathematical operations, data abstraction, and scaling computations across devices (CPUs, GPUs, and TPUs). Tensors can represent everything from scalars to high-dimensional data like images or videos. They flow through computational graphs, enabling optimization and auto-differentiation for machine learning tasks. Understanding tensor space is essential for effectively using TensorFlow."
      ],
      "metadata": {
        "id": "YQAElc-Au28F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7) How can TensorBoard be integrated with TensorFlow 2.0**"
      ],
      "metadata": {
        "id": "395sUw_lu4Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the required libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Define the log directory\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Initialize TensorBoard callback\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "# Create a simple model\n",
        "model = Sequential([\n",
        "    Dense(4, activation='relu', input_shape=(2,)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Example dataset\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, callbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZN8-bWwuNsT",
        "outputId": "4a0ba3b2-e741-418e-e4f2-b1088443c7db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.7595\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2500 - loss: 0.7583\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.2500 - loss: 0.7572\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2500 - loss: 0.7561\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.2500 - loss: 0.7550\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2500 - loss: 0.7539\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2500 - loss: 0.7528\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2500 - loss: 0.7517\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.2500 - loss: 0.7506\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2500 - loss: 0.7495\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2500 - loss: 0.7485\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2500 - loss: 0.7474\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2500 - loss: 0.7464\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2500 - loss: 0.7453\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2500 - loss: 0.7443\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.2500 - loss: 0.7433\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2500 - loss: 0.7423\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.2500 - loss: 0.7412\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.2500 - loss: 0.7402\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2500 - loss: 0.7393\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.2500 - loss: 0.7383\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2500 - loss: 0.7373\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2500 - loss: 0.7363\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2500 - loss: 0.7354\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2500 - loss: 0.7344\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2500 - loss: 0.7335\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2500 - loss: 0.7326\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2500 - loss: 0.7316\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2500 - loss: 0.7307\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2500 - loss: 0.7298\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.2500 - loss: 0.7289\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2500 - loss: 0.7280\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2500 - loss: 0.7271\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2500 - loss: 0.7263\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2500 - loss: 0.7254\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2500 - loss: 0.7245\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2500 - loss: 0.7237\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2500 - loss: 0.7229\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2500 - loss: 0.7220\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2500 - loss: 0.7212\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2500 - loss: 0.7204\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2500 - loss: 0.7196\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2500 - loss: 0.7188\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2500 - loss: 0.7180\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2500 - loss: 0.7172\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2500 - loss: 0.7164\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2500 - loss: 0.7157\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2500 - loss: 0.7149\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.2500 - loss: 0.7141\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.2500 - loss: 0.7134\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.2500 - loss: 0.7127\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.2500 - loss: 0.7119\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.2500 - loss: 0.7112\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.2500 - loss: 0.7105\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2500 - loss: 0.7098\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2500 - loss: 0.7091\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2500 - loss: 0.7084\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.2500 - loss: 0.7077\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.2500 - loss: 0.7070\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.2500 - loss: 0.7063\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.2500 - loss: 0.7057\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.2500 - loss: 0.7050\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.2500 - loss: 0.7044\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2500 - loss: 0.7037\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.2500 - loss: 0.7031\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.2500 - loss: 0.7024\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.2500 - loss: 0.7018\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2500 - loss: 0.7012\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.2500 - loss: 0.7006\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.2500 - loss: 0.7000\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.2500 - loss: 0.6993\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.2500 - loss: 0.6987\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.2500 - loss: 0.6982\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2500 - loss: 0.6976\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2500 - loss: 0.6970\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.2500 - loss: 0.6964\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.2500 - loss: 0.6958\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.2500 - loss: 0.6953\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.2500 - loss: 0.6947\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2500 - loss: 0.6942\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2500 - loss: 0.6936\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.2500 - loss: 0.6931\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2500 - loss: 0.6925\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.2500 - loss: 0.6920\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2500 - loss: 0.6915\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.2500 - loss: 0.6909\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2500 - loss: 0.6904\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.2500 - loss: 0.6899\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2500 - loss: 0.6894\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.2500 - loss: 0.6889\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2500 - loss: 0.6884\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.2500 - loss: 0.6879\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2500 - loss: 0.6874\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2500 - loss: 0.6869\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.2500 - loss: 0.6864\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.2500 - loss: 0.6859\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2500 - loss: 0.6854\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2500 - loss: 0.6850\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2500 - loss: 0.6845\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2500 - loss: 0.6840\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b3f19d55a20>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "k0NfkchFvl8Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8) What is the purpose of TensorFlow Playground**"
      ],
      "metadata": {
        "id": "ox2qRUuFwTmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow Playground  is an interactive web-based tool designed for educational purposes to help users understand and experiment with the fundamentals of machine learning, particularly neural networks. It provides a visual and intuitive way to explore how neural networks work and how different parameters and configurations affect their performance."
      ],
      "metadata": {
        "id": "g4LcLyMVwg11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9) What is Netron, and how is it useful for deep learning models**"
      ],
      "metadata": {
        "id": "FPyOBMPwwk_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netron is a powerful open source tool used for  visualising deep learning models and neural network architectures. It supports a wide variety of model formats and allows users to inspect and explore the structure of ml learning models, Such as layers,weights and other parameters, in an intuitive graphical interface"
      ],
      "metadata": {
        "id": "TOMx7COdwx0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10) What is the difference between TensorFlow and PyTorch**"
      ],
      "metadata": {
        "id": "YWFM5lLYx8Pg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow and PyTorch are both popular deep learning frameworks, but they differ in several key areas:\n",
        "\n",
        "* TensorFlow is known for its robust production capabilities, large ecosystem, and tools for deployment (like TensorFlow Lite and TensorFlow.js). It uses static computation graphs, though TensorFlow 2.0 introduced dynamic execution for easier debugging and flexibility.\n",
        "\n",
        "* PyTorch is favored for research due to its dynamic computation graph (define-by-run), making it more flexible and easier to debug. It's more intuitive and \"pythonic,\" and while it was initially research-focused, it has made strides in production deployment with tools like TorchServe.\n",
        "\n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "1roandVUy3wl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11) How do you install PyTorch**"
      ],
      "metadata": {
        "id": "XLOH-U6rzJjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install torch\n",
        "# pip install torch torchvision torchaudio\n",
        "\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz6hWfbnwJ9X",
        "outputId": "51d759d3-21d5-401a-e0e0-e0f5d978e96c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12) What is the basic structure of a PyTorch neural network**"
      ],
      "metadata": {
        "id": "xfT7T2LDzf5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic structure of a PyTorch neural network consists of the following components:\n",
        "1. Model Class:\n",
        "\n",
        "A neural network in PyTorch is typically defined as a class that inherits from torch.nn.Module. This class contains two essential methods:\n",
        "\n",
        "__init__(self): This method defines the layers of the network (like fully connected layers, activation functions, etc.).\n",
        "forward(self, x): This method defines how the input data flows through the network (how the data passes through each layer).\n",
        "\n",
        "2. Layers:\n",
        "\n",
        "PyTorch provides a variety of layers, such as fully connected layers (nn.Linear), convolutional layers (nn.Conv2d), activation functions (nn.ReLU, nn.Sigmoid), etc.\n",
        "3. Optimizer:\n",
        "\n",
        "The optimizer (e.g., torch.optim.SGD, torch.optim.Adam) is used to adjust the model parameters (weights) during training.\n",
        "4. Loss Function:\n",
        "\n",
        "PyTorch offers several loss functions (e.g., nn.CrossEntropyLoss, nn.MSELoss) to compute the error between predicted and actual values, which is used to guide the training process."
      ],
      "metadata": {
        "id": "Kux4-p0fz4Uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13) What is the significance of tensors in PyTorch**"
      ],
      "metadata": {
        "id": "ObHjtivkz7ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors in PyTorch are multi-dimensional arrays that are essential for deep learning tasks. They allow efficient storage and computation, especially on GPUs. Tensors support automatic differentiation for backpropagation, making them critical for training neural networks. They can easily be converted between PyTorch and NumPy, enabling seamless data manipulation across frameworks."
      ],
      "metadata": {
        "id": "DoIvDm0c0HAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **14) What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch**"
      ],
      "metadata": {
        "id": "251aenL80Ixr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between torch.Tensor and torch.cuda.Tensor in PyTorch lies in where the tensor is stored and processed:\n",
        "\n",
        " * torch.Tensor:\n",
        "      This is the default tensor type in PyTorch.\n",
        "      It is stored and processed on the CPU.\n",
        "      Operations involving torch.Tensor are executed on the CPU.\n",
        "\n",
        " * torch.cuda.Tensor:\n",
        "      These tensors are specifically designed to be stored and processed on the GPU (Graphics Processing Unit).\n",
        "      torch.cuda.Tensor is a tensor that resides on a CUDA-enabled GPU and takes advantage of GPU acceleration for faster computations.\n",
        "      You can create a tensor directly on the GPU using .to('cuda') or .cuda() methods.\n",
        "        "
      ],
      "metadata": {
        "id": "S5mK5T8-0Tlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15) What is the purpose of the torch.optim module in PyTorch**"
      ],
      "metadata": {
        "id": "pyf5JsXC0bHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The torch.optim module in PyTorch provides optimization algorithms that adjust model parameters (weights and biases) during training to minimize the loss function. It includes optimizers like SGD, Adam, and RMSprop, which help improve convergence and efficiency. These optimizers update the model's parameters based on gradients calculated during backpropagation."
      ],
      "metadata": {
        "id": "zOedpsMG0ppj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **16) What are some common activation functions used in neural networks**"
      ],
      "metadata": {
        "id": "HURX9RrD0q6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU (Rectified Linear Unit)\n",
        "\n",
        "Sigmoid\n",
        "\n",
        "Tanh (Hyperbolic Tangent)\n",
        "\n",
        "Softmax\n",
        "\n",
        "Leaky ReLU\n",
        "\n",
        "ELU (Exponential Linear Unit)\n",
        "\n",
        "PReLU (Parametric ReLU)"
      ],
      "metadata": {
        "id": "svBuriph01zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17) What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch**"
      ],
      "metadata": {
        "id": "fHZ_upgB0-Wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Flexibility: torch.nn.Module offers more flexibility, while torch.nn.Sequential is simpler and ideal for straightforward, sequential models.\n",
        "\n",
        "* Custom Operations: torch.nn.Module allows you to define custom layers, operations, and forward passes, whereas torch.nn.Sequential is limited to simple sequential layer stacks."
      ],
      "metadata": {
        "id": "vL4qLjdB1IGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **18) How can you monitor training progress in TensorFlow 2.0**"
      ],
      "metadata": {
        "id": "OmvO8FAm1OKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TensorBoard: Visualizes metrics like loss and accuracy in real-time.\n",
        "\n",
        "* Progress Bar: Displays a progress bar with verbose=1 or verbose=2 in model.fit().\n",
        "\n",
        "* Custom Callbacks: Track custom metrics or performance with user-defined callbacks.\n",
        "\n",
        "* Metrics in model.fit(): Directly monitor training metrics like loss and accuracy during training."
      ],
      "metadata": {
        "id": "e6rKFxW11UXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **19) How does the Keras API fit into TensorFlow 2.0**"
      ],
      "metadata": {
        "id": "OxRkj9CU1gcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow 2.0, Keras serves as the high-level API for building and training deep learning models. It offers an intuitive interface for defining models using the Sequential or Functional API, while leveraging TensorFlow’s backend for computation, optimization, and GPU support. Keras simplifies model creation, training, and evaluation, seamlessly integrating with other TensorFlow features like datasets, TensorFlow Lite, and TensorFlow Serving."
      ],
      "metadata": {
        "id": "XsrZ3yfB1s3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **20) What is an example of a deep learning project that can be implemented using TensorFlow 2.0**"
      ],
      "metadata": {
        "id": "9mY5INtb1ufK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of a deep learning project in TensorFlow 2.0 is an Image Classification Model using Convolutional Neural Networks (CNNs). The project involves training a CNN to classify images into categories, such as the CIFAR-10 dataset, which contains images of 10 different objects. The model is trained using the Adam optimizer and categorical cross-entropy loss, and its performance is evaluated using accuracy. TensorFlow 2.0 simplifies model creation, training, and evaluation, making it ideal for image classification tasks."
      ],
      "metadata": {
        "id": "wCW-sprT2CVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **21) What is the main advantage of using pre-trained models in TensorFlow and PyTorch**"
      ],
      "metadata": {
        "id": "KI_G4F1O2DZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main advantage of using pre-trained models in TensorFlow and PyTorch is transfer learning, which allows you to fine-tune models trained on large datasets for your specific task. This saves time, reduces computational resources, improves performance on smaller datasets, and simplifies implementation, as the model has already learned useful features that can be adapted to your problem."
      ],
      "metadata": {
        "id": "LlQlDPid2O4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***PRACTICAL***"
      ],
      "metadata": {
        "id": "z25RA7Ib2QNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1) How do you install and verify that TensorFlow 2.0 was installed successfully**"
      ],
      "metadata": {
        "id": "EV-ycNHgGblT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To install tensorflow\n",
        "\n",
        "# pip install tensorflow==2.0\n",
        "\n",
        "# Check the version of TensorFlow\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxcrtCcdzkWS",
        "outputId": "f7526baf-37d9-47c6-c821-134f8c5b9617"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2) How can you define a simple function in TensorFlow 2.0 to perform addition**"
      ],
      "metadata": {
        "id": "vhVTx_BuGv_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "@tf.function\n",
        "def add_numbers(a,b):\n",
        "  return a + b\n",
        "\n",
        "res = add_numbers(tf.constant(5),tf.constant(3))\n",
        "print(res.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jwGwVt_G1--",
        "outputId": "53f3b52a-622c-4cbf-9d11-88a37b1da1a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3) How can you create a simple neural network in TensorFlow 2.0 with one hidden layer**"
      ],
      "metadata": {
        "id": "nUO3R_z1Jpqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(2,)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "X = tf.constant([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=tf.float32)\n",
        "y = tf.constant([0, 0, 0, 1], dtype=tf.float32)\n",
        "\n",
        "model.fit(X, y, epochs=100)\n",
        "\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "predictions = model.predict(X)\n",
        "print(\"\\nPredictions:\")\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(f\"Input: {X[i]}, Predicted Output: {prediction[0]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MOx7EomHVTF",
        "outputId": "5f678282-e172-4838-b0f2-ea99acf60380"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6920\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6909\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6898\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6887\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6876\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6865\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6855\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6844\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6834\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6823\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6812\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6802\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6791\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6780\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6769\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6759\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6748\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6737\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6726\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6715\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6705\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6694\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6683\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6672\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6661\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6650\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6640\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6629\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6618\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6607\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6596\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6585\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6574\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6563\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6552\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6541\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6530\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6519\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6508\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6497\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6486\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6475\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6464\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6453\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6441\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6430\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6419\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6408\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6397\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6386\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6374\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6363\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6353\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6343\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6333\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6322\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6311\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6300\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6289\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6278\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6268\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.6257\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6247\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.6236\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.6225\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6214\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6204\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6192\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6182\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6172\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6161\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6150\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6139\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6128\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6117\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.6106\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6095\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.6084\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.6073\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6062\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6051\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6040\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6029\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6018\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6007\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.5996\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.5985\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.5974\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.5963\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5952\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.5941\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.5929\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.5918\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.5907\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.5896\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.5885\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.5873\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7500 - loss: 0.5862\n",
            "Loss: 0.5862265229225159, Accuracy: 0.75\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "Predictions:\n",
            "Input: [0. 0.], Predicted Output: 0.4460\n",
            "Input: [0. 1.], Predicted Output: 0.3290\n",
            "Input: [1. 0.], Predicted Output: 0.4722\n",
            "Input: [1. 1.], Predicted Output: 0.4885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4) How can you visualize the training progress using TensorFlow and Matplotlib**"
      ],
      "metadata": {
        "id": "eZeJ9oO2KMyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "history = model.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "loss = history.history['loss']\n",
        "accuracy = history.history['accuracy']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(loss, label='Loss', color='red')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(accuracy, label='Accuracy', color='blue')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "8iWpbdyDKKcO",
        "outputId": "a7d1f697-51dd-4aab-cce9-dfb559ed836e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b3f0762a230>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5) How do you install PyTorch and verify the PyTorch installation**"
      ],
      "metadata": {
        "id": "xccSUYR3K25e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To install\n",
        "#pip install torch torchvision torchaudio\n",
        "\n",
        "\n",
        "#To verify\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8WLgzZiKmFd",
        "outputId": "a44164f7-22d4-4d50-902a-d0f3dbfaec2d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6) How do you create a simple neural network in PyTorch**"
      ],
      "metadata": {
        "id": "RxyVg5f6LI0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the XOR inputs and outputs\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "# Define a simple neural network with 1 hidden layer\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 4),      # Input layer (2 inputs), Hidden layer (4 neurons)\n",
        "    nn.ReLU(),            # ReLU activation function\n",
        "    nn.Linear(4, 1),      # Output layer (1 neuron)\n",
        "    nn.Sigmoid()          # Sigmoid activation for binary output\n",
        ")\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    output = model(X)\n",
        "    loss = criterion(output, y)  # Calculate loss\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "    loss.backward()        # Compute gradients\n",
        "    optimizer.step()       # Update weights\n",
        "\n",
        "    # Print loss every 1000 epochs\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model after training\n",
        "with torch.no_grad():\n",
        "    predictions = model(X)\n",
        "    predictions = predictions.round()  # Round the output to 0 or 1\n",
        "    print(\"\\nPredictions after training:\")\n",
        "    print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gfAkzXmLHvo",
        "outputId": "c1371e3c-4647-400d-8cb3-ebba1888f51e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1000/10000], Loss: 0.0198\n",
            "Epoch [2000/10000], Loss: 0.0054\n",
            "Epoch [3000/10000], Loss: 0.0029\n",
            "Epoch [4000/10000], Loss: 0.0019\n",
            "Epoch [5000/10000], Loss: 0.0014\n",
            "Epoch [6000/10000], Loss: 0.0011\n",
            "Epoch [7000/10000], Loss: 0.0009\n",
            "Epoch [8000/10000], Loss: 0.0008\n",
            "Epoch [9000/10000], Loss: 0.0007\n",
            "Epoch [10000/10000], Loss: 0.0006\n",
            "\n",
            "Predictions after training:\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7) How do you define a loss function and optimizer in PyTorch**"
      ],
      "metadata": {
        "id": "uK7TmxtfLciI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple model (e.g., 1 hidden layer neural network)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 4),      # Input layer (2 inputs), Hidden layer (4 neurons)\n",
        "    nn.ReLU(),            # ReLU activation function\n",
        "    nn.Linear(4, 1),      # Output layer (1 neuron)\n",
        "    nn.Sigmoid()          # Sigmoid activation for binary output\n",
        ")\n",
        "\n",
        "# Loss function: Binary Cross-Entropy Loss (for binary classification)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizer: Stochastic Gradient Descent (SGD)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "uJAXLgCCLhQU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8) How do you implement a custom loss function in PyTorch**"
      ],
      "metadata": {
        "id": "_j_7_jo-LuzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Custom loss function class\n",
        "class CustomMSLELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMSLELoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_true, y_pred):\n",
        "        # Apply log transformation to the true and predicted values\n",
        "        log_y_true = torch.log(y_true + 1)\n",
        "        log_y_pred = torch.log(y_pred + 1)\n",
        "\n",
        "        # Compute the squared difference between log-transformed values\n",
        "        loss = torch.mean((log_y_true - log_y_pred) ** 2)\n",
        "        return loss\n",
        "\n",
        "# Example usage of custom loss function\n",
        "y_true = torch.tensor([1.0, 2.0, 3.0, 4.0], dtype=torch.float32)  # True labels\n",
        "y_pred = torch.tensor([1.2, 2.1, 2.8, 3.9], dtype=torch.float32)  # Predicted values\n",
        "\n",
        "# Initialize the custom loss function\n",
        "criterion = CustomMSLELoss()\n",
        "\n",
        "# Calculate the loss\n",
        "loss = criterion(y_true, y_pred)\n",
        "print(f\"Custom MSLE Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ2Ca3TVLuDs",
        "outputId": "1b13249f-fd21-4efb-acf5-fa879bc3460b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom MSLE Loss: 0.0032995876390486956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9) How do you save and load a TensorFlow model**"
      ],
      "metadata": {
        "id": "gw7C2oUOL6mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model (Example with dummy data)\n",
        "X_train = tf.random.normal((1000, 784))\n",
        "y_train = tf.random.uniform((1000,), minval=0, maxval=10, dtype=tf.int32)\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "# Save the model\n",
        "model.save('my_model.h5')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtApfBOoL_1z",
        "outputId": "39d40c6c-59df-4870-ebcd-34c196a642da"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0862 - loss: 3.0106\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3900 - loss: 1.8232\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 1.2331\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9038 - loss: 0.8734\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9633 - loss: 0.5891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mdcpc3wUMG_e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}